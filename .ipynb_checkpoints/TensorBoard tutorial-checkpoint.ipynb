{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the training precces of a Linear model using TensorBoard\n",
    "\n",
    "Same data set as the one used in the \"Multivariate linear regression PyTorch Tutorial.ipynb notebook\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from utils import linear_model, SSE\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "### Data ###\n",
    "\n",
    "w_true = torch.tensor(np.array([3.,6.,9.]))       \n",
    "b_true = torch.tensor([3.])                       \n",
    "X_true = torch.tensor(np.linspace((0,1,2),(1,2,3),10))\n",
    "Y_true = linear_model(X_true,w_true,b_true)\n",
    "\n",
    "Y_obs = torch.add(Y_true, torch.randn(Y_true.shape))\n",
    "\n",
    "\n",
    "### Model Parameters ###\n",
    "\n",
    "w_hat = torch.randn(w_true.shape, dtype=torch.float64, requires_grad=True) \n",
    "b_hat = torch.randn(1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\n",
    "### Hyperparamters ### \n",
    "\n",
    "### alpha = bad (small). ###\n",
    "alpha  = 0.0000001     # Learning rate.\n",
    "n_iter = 10000         # Time steps (epochs).\n",
    "optimizer = optim.SGD([w_hat, b_hat], lr=alpha) \n",
    "\n",
    "\n",
    "### Main Optimization Loop ###\n",
    "\n",
    "for t in range(n_iter):               \n",
    "    optimizer.zero_grad()                                         # Set the gradients to zero.   \n",
    "    current_loss = loss(linear_model(X_true, w_hat, b_hat),Y_obs) # For tracking the loss.\n",
    "    current_loss.backward()                                       # Compute gradients of loss function (scalar-vector).\n",
    "    optimizer.step()                                              # Update W_hat and b_hat.\n",
    "    if t % 1000 == 0 :\n",
    "        print(f\"t = {t}, loss = {current_loss}, W_hat = {w_hat.detach().numpy()}, b_hat = {b_hat.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview and installation\n",
    "\n",
    "TensorBoard is part of TensorFlow and offers a framework for visualizing and monitoring the training process. It is useful for visualizing the computational graph of nn models, scalars (loss, classification accuracy), and distributions (weights of the model). \n",
    "\n",
    "**Check installation**\n",
    "```python\n",
    ">> conda list | grep tensor\n",
    ">> pip list | grep tensor\n",
    "```\n",
    "\n",
    "**Install**\n",
    "```python\n",
    "# Using anaconda package manager\n",
    ">> conda install tensorflow\n",
    "\n",
    "# Using pip\n",
    ">> pip install --upgrade pip\n",
    ">> pip install tensorflow\n",
    "```\n",
    "\n",
    "**Check instalation**\n",
    "```python\n",
    ">> which tensorboard\n",
    "```\n",
    "\n",
    "# Defining summaries\n",
    "\n",
    "??? are objects understood by TensorBoard that we want to display. There are various objects depending on what we want to visualize: <br>\n",
    "- scalars (gradients, loss)\n",
    "- vectors/histogram (model parameters - weights and biases) <br>\n",
    "\n",
    "Furthermore, you can use tf.name_scope to group scalars on the board. That is, scalars having the same name scope will be displayed on the same row. Here you define three different summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:40: UserWarning: h5py is running against HDF5 1.10.5 when it was built against 1.10.4, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    }
   ],
   "source": [
    "### Re-do with TensoBoard ###\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# alpha = good one.\n",
    "#Define log directory; we use current time to differentiate runs\n",
    "# current_time = time.strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "# logs_path = \"/path/to/directory/\" + current_time\n",
    "# writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting TensorBoard\n",
    "\n",
    "**From the terminal**\n",
    "```python\n",
    "# If in the firectory where ? is saved\n",
    ">> tensorboard --logdir\n",
    "\n",
    "# Otherwise\n",
    ">> tensorboard --logdir /path/to/directory/\n",
    "```\n",
    "\n",
    "**From the notebook**\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /path/to/directory/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- https://www.tensorflow.org/install\n",
    "- https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
