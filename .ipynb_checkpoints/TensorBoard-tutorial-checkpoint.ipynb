{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the training procces of a Linear model using TensorBoard\n",
    "\n",
    "### Note:\n",
    "- Same data set as the one used in [this notebook](Multivariate_linear_regression_PyTorch_Tutorial.ipynb).\n",
    "- [This](TensorBoard-tutorial.py) is the python script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview and installation\n",
    "\n",
    "TensorBoard is part of TensorFlow and offers a framework for visualizing and monitoring the training process. It is useful for visualizing the computational graph of nn models, scalars (loss, classification accuracy), and distributions (weights of the model). \n",
    "\n",
    "**Check installation**\n",
    "```python\n",
    ">> conda list | grep tensor\n",
    ">> pip list | grep tensor\n",
    "```\n",
    "\n",
    "**Install**\n",
    "```python\n",
    "# Using anaconda package manager\n",
    ">> conda install tensorflow\n",
    "\n",
    "# Using pip\n",
    ">> pip install --upgrade pip\n",
    ">> pip install tensorflow\n",
    "```\n",
    "\n",
    "**Check instalation**\n",
    "```python\n",
    ">> conda list | grep tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter #Class to log data.\n",
    "from utils import linear_model, SSE\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "### Data ###\n",
    "\n",
    "w_true = torch.tensor(np.array([3.,6.,9.]))       \n",
    "b_true = torch.tensor([3.])                       \n",
    "X_true = torch.tensor(np.linspace((0,1,2),(1,2,3),10))\n",
    "Y_true = linear_model(X_true,w_true,b_true)\n",
    "\n",
    "Y_obs = torch.add(Y_true, torch.randn(Y_true.shape))\n",
    "\n",
    "\n",
    "### Model Parameters ###\n",
    "\n",
    "w_hat = torch.randn(w_true.shape, dtype=torch.float64, requires_grad=True) \n",
    "b_hat = torch.randn(1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\n",
    "### Hyperparamters ### \n",
    "\n",
    "alpha  = 0.005      # Learning rate.\n",
    "n_iter = 10000         # Time steps (epochs).\n",
    "optimizer = optim.SGD\n",
    "\n",
    "\n",
    "### TensorBoard Writer Setup ###\n",
    "\n",
    "# We tell Pytorch where to save a log of the trained weights and loss values.\n",
    "log_name = f\"{optimizer.__name__}_alpha={alpha}\"\n",
    "writer = SummaryWriter(log_dir=f\"runs/{log_name}\")\n",
    "\n",
    "\n",
    "### Main Optimization Loop ###\n",
    "\n",
    "optimizer = optim.SGD([w_hat, b_hat], lr=alpha) \n",
    "\n",
    "for t in range(n_iter):               \n",
    "    optimizer.zero_grad()                                         # Set the gradients to zero.   \n",
    "    current_loss = SSE(linear_model(X_true, w_hat, b_hat),Y_obs)  # For tracking the loss.\n",
    "    current_loss.backward()                                       # Compute gradients of loss function (scalar-vector).\n",
    "    optimizer.step()                                              # Update W_hat and b_hat.\n",
    "    #if t % 1000 == 0 :\n",
    "        #print(f\"t = {t}, loss = {current_loss}, W_hat = {w_hat.detach().numpy()}, b_hat = {b_hat.item()}\")\n",
    "\n",
    "    # Write the current values of the weights, and loss to the log.\n",
    "    # global_step=t tells tensorboard at what step of the training this is.\n",
    "    writer.add_scalar('bias', b_hat, global_step=t)\n",
    "    writer.add_scalar('w_1', w_hat[0], global_step=t)\n",
    "    writer.add_scalar('w_2', w_hat[1], global_step=t)\n",
    "    writer.add_scalar('w_3', w_hat[2], global_step=t)\n",
    "    writer.add_scalar('L', current_loss, global_step=t)\n",
    "\n",
    "writer.close() # After we are done with the writer, we should close the log file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting TensorBoard\n",
    "\n",
    "**From the terminal**\n",
    "```python\n",
    "# Relative path\n",
    ">> tensorboard --logdir=runs/\n",
    ">> tensorboard --logdir=runs/ --host localhost --port 8088\n",
    "\n",
    "# Absolute path\n",
    ">> tensorboard --logdir=/path/to/directory/\n",
    "```\n",
    "\n",
    "**From the notebook**\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=/path/to/directory/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- https://www.tensorflow.org/install\n",
    "- https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/\n",
    "- https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2017-12-27-optimization.html\n",
    "- https://pytorch.org/docs/stable/tensorboard.html#:~:text=The%20SummaryWriter%20class%20provides%20a,summaries%20and%20events%20to%20it.&text=Use%20hierarchical%20folder%20structure%20to,experiment%20to%20compare%20across%20them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
